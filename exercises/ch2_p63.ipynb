{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ch2 p63\n",
    "\n",
    "At the end of SS 2.12, it is suggested that it would be more efficient to avoid recomputing the partials at each step of Newton's method for a nonlinear system, doing it only after each nth step when there are n equations. Redo p59 and p62 using this modification. Compare the rate of convergence with that when the partials are recomputed at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from naf.linalg_exp import gedo, dosv, set_options\n",
    "import math\n",
    "import time\n",
    "\n",
    "set_options(precision=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p59 Redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_m(z):\n",
    "    x = z[0]\n",
    "    y = z[1]\n",
    "    \n",
    "    dxf1 = lambda x,y: 2.0*x + 1.0\n",
    "    dyf1 = lambda x,y: -2.0*y\n",
    "    dxf2 = lambda x,y: -2.0*x*math.cos(math.pow(x,2))\n",
    "    dyf2 = lambda x,y: 1.0\n",
    "    \n",
    "    return np.array([[dxf1(x,y),dyf1(x,y)],[dxf2(x,y),dyf2(x,y)]])\n",
    "\n",
    "def b_v(z):\n",
    "    x = z[0]\n",
    "    y = z[1]\n",
    "    \n",
    "    f1 = lambda x,y: math.pow(x,2) + x - math.pow(y,2) - 1\n",
    "    f2 = lambda x,y: y - math.sin(math.pow(x,2))\n",
    "    return np.array([f1(x,y),f2(x,y)])\n",
    "\n",
    "def newton_soe(x0, a_m, b_m, tol= 0.0001, max_iter=20, verbose=False):\n",
    "    \"\"\"Netwon's method applied for a system of nonlinear equations\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x0 : 1D numpy array\n",
    "        initial estimate of solution vector\n",
    "    a_m : function\n",
    "        function that accepts 1D numpy array of the approx. solution vector\n",
    "        and returns the Jacobian matrix of the funcitons (a 2D numpy array \n",
    "        of the partial derivatives evaluated at the approx. solution vector)\n",
    "    b_v : function\n",
    "        function that accepts 1D numpy array of the approx. solution vector\n",
    "        and returns a 2D numpy array of the functions evaluated at the approx.\n",
    "        solution vector)\n",
    "    tol : float, optional\n",
    "        convergence tolerance. The default is 0.0001\n",
    "    max_iter : integer, optional\n",
    "        maximum number of iterations to perform if the solution is not converging.\n",
    "        The default is 20.\n",
    "    verbose : bool, optional\n",
    "        outputs a summary of the solution progression at each solution step\n",
    "        The default is False\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    x0 : 1D numpy array\n",
    "        approx. solution to the system within the specified tolerance\n",
    "    dx : 1D numpy array\n",
    "        solution error w.r.t. the previous approx. solution\n",
    "    num_iter : integer\n",
    "        number of iterations required to converge.\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    Example a_m function:\n",
    "    \n",
    "    def a_m(z):\n",
    "        x = z[0]\n",
    "        y = z[1]\n",
    "\n",
    "        dxf1 = lambda x,y: 2.0*x + 1.0\n",
    "        dyf1 = lambda x,y: -2.0*y\n",
    "        dxf2 = lambda x,y: -2.0*x*math.cos(math.pow(x,2))\n",
    "        dyf2 = lambda x,y: 1.0\n",
    "\n",
    "        return np.array([[dxf1(x,y),dyf1(x,y)],[dxf2(x,y),dyf2(x,y)]])\n",
    "    \n",
    "    Example b_m function:\n",
    "    \n",
    "    def b_v(z):\n",
    "        x = z[0]\n",
    "        y = z[1]\n",
    "\n",
    "        f1 = lambda x,y: math.pow(x,2) + x - math.pow(y,2) - 1\n",
    "        f2 = lambda x,y: y - math.sin(math.pow(x,2))\n",
    "        return np.array([f1(x,y),f2(x,y)])   \n",
    "    \"\"\"\n",
    "\n",
    "    num_eqs = np.size(x0)\n",
    "    tol = np.full(num_eqs, 0.0001)\n",
    "    dx = tol*10\n",
    "    num_iter = 0\n",
    "    max_iter = 20\n",
    "\n",
    "    while np.all(abs(dx)>tol) and num_iter < max_iter:\n",
    "        a = a_m(x0)\n",
    "\n",
    "        b = -1*b_v(x0)\n",
    "\n",
    "        lu, ov = gedo(a)\n",
    "        dx = dosv(lu, ov, b)[ov]\n",
    "\n",
    "        x0 = x0 + dx\n",
    "        num_iter += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f'a: {a}')\n",
    "            print(f'b: {b}')\n",
    "            print(f'lu,ov: {lu},{ov}')\n",
    "            print(f'dx: {dx}')\n",
    "            print(f'x0: {x0}')\n",
    "            print(f'num_iter: {num_iter}')\n",
    "            print('\\n')\n",
    "                \n",
    "    return x0, dx, num_iter\n",
    "\n",
    "def newton_soem(x0, a_m, b_m, num_eqs, n, tol= 0.0001, max_iter=20, verbose=False):\n",
    "    \"\"\"Modified Newton's method applied to a system of nonlinear equations\n",
    "    \n",
    "    The modification in the solution routine is not updating the Jacobian matrix\n",
    "    of partials with each iteration. Instead the same Jacobian is used to without\n",
    "    update with the new approximate solution. The Jacobian is updated after n\n",
    "    iterations with the first Jacobian. Using the same Jacobian for multiple \n",
    "    iteration steps saves on re-evaluation the potentially large number of \n",
    "    functions in the Jacobian matrix. This is a trade off with the number of \n",
    "    steps required to converage.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x0 : 1D numpy array\n",
    "        initial estimate of solution vector\n",
    "    a_m : function\n",
    "        function that accepts 1D numpy array of the approx. solution vector\n",
    "        and returns the Jacobian matrix of the funcitons (a 2D numpy array \n",
    "        of the partial derivatives evaluated at the approx. solution vector)\n",
    "    b_v : function\n",
    "        function that accepts 1D numpy array of the approx. solution vector\n",
    "        and returns a 2D numpy array of the functions evaluated at the approx.\n",
    "        solution vector)\n",
    "    num_eqs : integer\n",
    "        number of equations in the system\n",
    "    n : integer\n",
    "        number of iterations to use the same Jacobian w/o update (a good starting\n",
    "        point is the number of functions in the system)\n",
    "    tol : float, optional\n",
    "        convergence tolerance. The default is 0.0001\n",
    "    max_iter : integer, optional\n",
    "        maximum number of iterations to perform if the solution is not converging.\n",
    "        The default is 20.\n",
    "    verbose : bool, optional\n",
    "        outputs a summary of the solution progression at each solution step.\n",
    "        The default is False.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    x0 : 1D numpy array\n",
    "        approx. solution to the system within the specified tolerance\n",
    "    dx : 1D numpy array\n",
    "        solution error w.r.t. the previous approx. solution\n",
    "    num_iter : integer\n",
    "        number of iterations required to converge.\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    Example a_m function:\n",
    "    \n",
    "    def a_m(z):\n",
    "        x = z[0]\n",
    "        y = z[1]\n",
    "\n",
    "        dxf1 = lambda x,y: 2.0*x + 1.0\n",
    "        dyf1 = lambda x,y: -2.0*y\n",
    "        dxf2 = lambda x,y: -2.0*x*math.cos(math.pow(x,2))\n",
    "        dyf2 = lambda x,y: 1.0\n",
    "\n",
    "        return np.array([[dxf1(x,y),dyf1(x,y)],[dxf2(x,y),dyf2(x,y)]])\n",
    "    \n",
    "    Example b_m function:\n",
    "    \n",
    "    def b_v(z):\n",
    "        x = z[0]\n",
    "        y = z[1]\n",
    "\n",
    "        f1 = lambda x,y: math.pow(x,2) + x - math.pow(y,2) - 1\n",
    "        f2 = lambda x,y: y - math.sin(math.pow(x,2))\n",
    "        return np.array([f1(x,y),f2(x,y)])   \n",
    "    \"\"\"\n",
    "    \n",
    "    tol = np.full(num_eqs, 0.0001)\n",
    "    dx = tol*10\n",
    "    num_iter = 0\n",
    "    max_iter = 20\n",
    "\n",
    "    while np.all(abs(dx)>tol) and num_iter < max_iter:\n",
    "        a = a_m(x0)\n",
    "        i = 0\n",
    "        \n",
    "        while np.all(abs(dx)>tol) and i <= n and num_iter < max_iter:\n",
    "            b = -1*b_v(x0)\n",
    "\n",
    "            lu, ov = gedo(a)\n",
    "            dx = dosv(lu, ov, b)[ov]\n",
    "\n",
    "            x0 = x0 + dx\n",
    "            \n",
    "            i += 1\n",
    "            num_iter += 1\n",
    "\n",
    "            if verbose:\n",
    "                print(f'a: {a}')\n",
    "                print(f'b: {b}')\n",
    "                print(f'lu,ov: {lu},{ov}')\n",
    "                print(f'dx: {dx}')\n",
    "                print(f'x0: {x0}')\n",
    "                print(f'num_iter: {num_iter}')\n",
    "                print('\\n')\n",
    "\n",
    "    return x0, dx, num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.67009  0.34514] [ 2.0e-05 -1.6e-04] 4 0.0012443065643310547\n",
      "[-1.67009  0.34514] [-4.0e-05 -2.2e-04] 5 0.0010864734649658203\n",
      "\n",
      "\n",
      "[0.72595 0.50295] [2.e-05 4.e-05] 4 0.0007822513580322266\n",
      "[0.72596 0.50296] [5.0e-05 2.1e-04] 5 0.0008466243743896484\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "z1 = np.array([-2.0,1.0])\n",
    "x1, dx1, ni1 = newton_soe(z1, a_m, b_v, verbose=False)\n",
    "end = time.time()\n",
    "print(x1, dx1, ni1, end-start)\n",
    "\n",
    "start = time.time()\n",
    "z1 = np.array([-2.0,1.0])\n",
    "x1, dx1, ni1 = newton_soem(z1, a_m, b_v, 2, 2, verbose=False)\n",
    "end = time.time()\n",
    "print(x1, dx1, ni1, end-start)\n",
    "\n",
    "print('\\n')\n",
    "start = time.time()\n",
    "z2 = np.array([1.0, 1.0])\n",
    "x2, dx2, ni2 = newton_soe(z2, a_m, b_v, verbose=False)\n",
    "end = time.time()\n",
    "print(x2, dx2, ni2, end-start)\n",
    "\n",
    "start = time.time()\n",
    "z2 = np.array([1.0, 1.0])\n",
    "x2, dx2, ni2 = newton_soem(z2, a_m, b_v, 2, 2, verbose=False)\n",
    "end = time.time()\n",
    "print(x2, dx2, ni2, end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:\n",
    "First, a note on implementation of the modified method. I noticed that instead of having a \"dumb\" for-loop for the inner iteration loop you could replace it with a \"smarter\" while-loop to potentially reduce the number of iterations if the solution converages to an acceptable tolerance while in the inner loop. I don't know if this was an intented part of the exercise and influences my discussion below. \n",
    "\n",
    "There doesn't appear to be a significant advantage of one method over another in this example. It is only one additional iteration for the modified method. Additionally, I am not looking at time to compute, cpu usage, or memory usage here. These may eludicate a significant advantage of one over the other. But again the problem is so small that it may be impossible to draw significant conclusions. \n",
    "\n",
    "I went back and timed it. A thousandth of a second or less. I don't know if I can draw conclusions from that. I think there is a way to run thousands of iterations of each of these and compare average run times which may provide some insight. Another day perhaps. My focus here is learning the how the algorithms work and how to program them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p62 Redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90221 1.10034 0.95013] [-2.e-05 -1.e-05  0.e+00] 3 0.0010671615600585938\n",
      "\n",
      "\n",
      "[0.90223 1.10034 0.95013] [-3.e-05 -6.e-05  1.e-05] 4 0.001964569091796875\n"
     ]
    }
   ],
   "source": [
    "def a_m(w):\n",
    "    x = w[0]\n",
    "    y = w[1]\n",
    "    z = w[2]\n",
    "    \n",
    "    dxf1 = lambda x,y,z: y*z - 2*x\n",
    "    dyf1 = lambda x,y,z: x*z + 2*y\n",
    "    dzf1 = lambda x,y,z: x*y\n",
    "\n",
    "    dxf2 = lambda x,y,z: y\n",
    "    dyf2 = lambda x,y,z: x\n",
    "    dzf2 = lambda x,y,z: -2.0*z\n",
    "\n",
    "    dxf3 = lambda x,y,z: math.exp(x)\n",
    "    dyf3 = lambda x,y,z: -1.0*math.exp(y)\n",
    "    dzf3 = lambda x,y,z: 1.0\n",
    "\n",
    "    return np.array([[dxf1(x,y,z), dyf1(x,y,z), dzf1(x,y,z)],\n",
    "                     [dxf2(x,y,z), dyf2(x,y,z), dzf2(x,y,z)],\n",
    "                     [dxf3(x,y,z), dyf3(x,y,z), dzf3(x,y,z)]])\n",
    "\n",
    "def b_v(w):\n",
    "    x = w[0]\n",
    "    y = w[1]\n",
    "    z = w[2]\n",
    "    \n",
    "    f1 = lambda x,y,z: x*y*z - x**2 + y**2 - 1.34\n",
    "    f2 = lambda x,y,z: x*y - z**2 - 0.09\n",
    "    f3 = lambda x,y,z: math.exp(x) - math.exp(y) + z - 0.41\n",
    "    \n",
    "    return np.array([f1(x,y,z), f2(x,y,z), f3(x,y,z)])\n",
    "\n",
    "start = time.time()\n",
    "w1 = np.array([1.0,1.0,1.0], dtype=float)\n",
    "x1,dx1,ni1 = newton_soe(w1, a_m, b_v)\n",
    "end = time.time()\n",
    "print(x1,dx1,ni1, end-start)\n",
    "\n",
    "print('\\n')\n",
    "start = time.time()\n",
    "w1 = np.array([1.0,1.0,1.0], dtype=float)\n",
    "x1,dx1,ni1 = newton_soem(w1, a_m, b_v, 3, 3)\n",
    "end = time.time()\n",
    "print(x1,dx1,ni1, end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:\n",
    "Similar to above. No great differences in number of iterations, no real advantages seen for this type or size of problem. Possibly with the consideration of compute time, cpu or memory usage differences may be revealed. However, with this small problem I doubt any real conclusions can be reached. \n",
    "\n",
    "It is obvious that fewer function evaluations are needed in the modified "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
